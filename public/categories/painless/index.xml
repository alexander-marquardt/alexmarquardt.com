<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Painless on Alexander Marquardt</title>
    <link>http://localhost:1313/categories/painless/</link>
    <description>Recent content in Painless on Alexander Marquardt</description>
    <generator>Hugo -- 0.153.4</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 06 Nov 2020 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/categories/painless/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Using Elasticsearch Painless scripting to recursively iterate through JSON fields</title>
      <link>http://localhost:1313/elastic/using-elasticsearch-painless-scripting-to-recursively-iterate-through-json-fields/</link>
      <pubDate>Fri, 06 Nov 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/elastic/using-elasticsearch-painless-scripting-to-recursively-iterate-through-json-fields/</guid>
      <description>&lt;h2 id=&#34;authors&#34;&gt;Authors&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Alexander Marquardt&lt;/li&gt;
&lt;li&gt;Honza Kral&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/master/modules-scripting-painless.html&#34;&gt;Painless&lt;/a&gt;&lt;/em&gt; is a simple, secure scripting language designed specifically for use with Elasticsearch. It is the default scripting language for Elasticsearch and can safely be used for inline and stored scripts. In one of its many use cases, Painless can modify documents as they are ingested into your Elasticsearch cluster. In this use case, you may find that you would like to use Painless to evaluate every field in each document that is received by Elasticsearch. However, because of the hierarchical nature of JSON documents, how to iterate over all of the fields may be non-obvious.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Using Logstash and Elasticsearch scripted upserts to transform eCommerce purchasing data</title>
      <link>http://localhost:1313/elastic/using-logstash-and-elasticsearch-scripted-upserts-to-transform-ecommerce-purchasing-data/</link>
      <pubDate>Tue, 17 Dec 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/elastic/using-logstash-and-elasticsearch-scripted-upserts-to-transform-ecommerce-purchasing-data/</guid>
      <description>&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/logstash/7.5/introduction.html&#34;&gt;Logstash&lt;/a&gt; is a tool that can be used to collect, process, and forward events to Elasticsearch. In order to demonstrate the power of Logstash when used in conjunction with Elasticsearch’s &lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/7.5/docs-update.html#scripted_upsert&#34;&gt;scripted upserts&lt;/a&gt;, I will show you how to create a near-real-time &lt;a href=&#34;https://www.elastic.co/elasticon/2015/sf/building-entity-centric-indexes&#34;&gt;entity-centric index&lt;/a&gt;. Once data is transformed into an entity-centric index, many kinds of analysis become possible with simple (cheap) queries rather than more computationally intensive aggregations.&lt;/p&gt;
&lt;p&gt;As a note, using the approach demonstrated here would result in documents similar to those generated by &lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/7.5/transforms.html&#34;&gt;Elasticsearch transforms&lt;/a&gt;. Nevertheless, the technique that is documented has not been benchmarked against Elasticsearch transforms, as the main goal of this blog is to demonstrate the power and flexibility of Logstash combined with scripted upserts.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>

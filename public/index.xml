<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Alexander Marquardt</title>
    <link>http://localhost:1313/</link>
    <description>Recent content on Alexander Marquardt</description>
    <generator>Hugo -- 0.153.4</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 26 Dec 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title></title>
      <link>http://localhost:1313/personal/other-areas-of-interest/</link>
      <pubDate>Fri, 26 Dec 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/personal/other-areas-of-interest/</guid>
      <description>&lt;h1 id=&#34;other-areas-of-interest&#34;&gt;Other Areas of Interest&lt;/h1&gt;
&lt;h2 id=&#34;finance&#34;&gt;Finance&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://alexmarquardt.com/2019/07/27/financial-implications-of-exercising-share-options/&#34;&gt;Financial implications of exercising share options&lt;/a&gt; (Jul 27, 2019)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;general-productivitytech-related&#34;&gt;General productivity/tech-related&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://alexmarquardt.com/cut-and-paste-a-table-from-google-sheets-into-an-html-document-no-code-required/&#34;&gt;Cut and paste a table from Google Sheets into an HTML document – no code required&lt;/a&gt; (Oct 10, 2022)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;nutrition&#34;&gt;Nutrition&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;http://alexmarquardt.com/2019/07/30/how-to-mitigate-hangovers/&#34;&gt;How to mitigate hangovers&lt;/a&gt; (Jul 31, 2019)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://alexmarquardt.com/2021/06/01/a-summary-of-recent-research-on-increasing-lifespan/&#34;&gt;A summary of recent research on increasing lifespan&lt;/a&gt; (June 1, 2021)&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;tourism-and-travel&#34;&gt;Tourism and Travel&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://alexmarquardt.com/2024/04/21/barcelona-a-personal-guide/&#34;&gt;Barcelona: A Personal Guide&lt;/a&gt; (April 21, 2024)&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:1313/professional/scientific-publications-patents-awards-and-education/</link>
      <pubDate>Fri, 26 Dec 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/professional/scientific-publications-patents-awards-and-education/</guid>
      <description>&lt;h1 id=&#34;professional-record-and-publications&#34;&gt;Professional Record and Publications&lt;/h1&gt;
&lt;p&gt;This page provides supporting material for my professional background, including selected publications, patents, open-source contributions, and formal education.&lt;/p&gt;
&lt;h2 id=&#34;profiles&#34;&gt;Profiles&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.linkedin.com/in/alexandermarquardt/&#34;&gt;LinkedIn Profile&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/alexander-marquardt/&#34;&gt;Github page&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;recognition&#34;&gt;Recognition&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Author of three papers that were selected to be amongst the &lt;a href=&#34;https://tcfpga.org/books/recommended-reading/page/fpga-20-reading-list&#34;&gt;25 most significant FPGA papers of the past 20 years&lt;/a&gt; at the 20th anniversary of the International Symposium on Field-Programmable Gate Arrays in 2012.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;scientific-publications&#34;&gt;Scientific Publications&lt;/h2&gt;
&lt;p&gt;The publications listed below have been &lt;strong&gt;cited over 3600 times&lt;/strong&gt; according to &lt;a href=&#34;https://scholar.google.co.uk/citations?user=d-dosjEAAAAJ&amp;amp;hl=en&#34;&gt;Google Scholar.&lt;/a&gt; These publications reflect early work in FPGA architecture, placement, and routing algorithms.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Ranking by Profit and Popularity in Elasticsearch</title>
      <link>http://localhost:1313/elastic/ranking-by-profit-and-popularity-in-elasticsearch/</link>
      <pubDate>Wed, 29 Oct 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/elastic/ranking-by-profit-and-popularity-in-elasticsearch/</guid>
      <description>&lt;p&gt;Moved to Elastic&amp;rsquo;s blog - &lt;a href=&#34;https://www.elastic.co/search-labs/blog/function-score-query-boosting-profit-popularity-elasticsearch&#34;&gt;https://www.elastic.co/search-labs/blog/function-score-query-boosting-profit-popularity-elasticsearch&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Personalizing e-commerce search results based on purchase history in Elasticsearch (Without a need for Machine Learning Post Processing)</title>
      <link>http://localhost:1313/elastic/personalizing-search-in-elasticsearch-without-ml-post-processing/</link>
      <pubDate>Fri, 12 Sep 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/elastic/personalizing-search-in-elasticsearch-without-ml-post-processing/</guid>
      <description>&lt;p&gt;Whether you’re looking for a product in an online store, an article in a news archive, or a file in a company knowledge base, the quality of the search experience determines how quickly you find what you need. Behind the scenes, many of these systems are powered by &lt;strong&gt;Elasticsearch&lt;/strong&gt;, a popular open-source search engine designed to handle large volumes of data and return relevant results in milliseconds.&lt;/p&gt;
&lt;p&gt;At its core, Elasticsearch matches user queries against text fields and ranks results using relevance scoring. But search doesn’t have to stop there. That’s where &lt;strong&gt;personalization&lt;/strong&gt; comes in. By incorporating signals such as past purchases, browsing behavior, or recent activity, search results can be adjusted so the items most relevant to &lt;em&gt;you&lt;/em&gt; appear higher. For example, if two people both search for &lt;em&gt;“chips”&lt;/em&gt;, one might see &lt;em&gt;classic potato chips&lt;/em&gt; at the top, while the other sees &lt;em&gt;crispy thin-cut chips&lt;/em&gt;, depending on their history.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Efficient bitwise matching of documents in Elasticsearch</title>
      <link>http://localhost:1313/elastic/efficient-bitwise-matching-of-documents-in-elasticsearch/</link>
      <pubDate>Sat, 15 Jun 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/elastic/efficient-bitwise-matching-of-documents-in-elasticsearch/</guid>
      <description>&lt;p&gt;This article has now been published on Elastic&amp;rsquo;s website. Please check it out at: &lt;a href=&#34;https://www.elastic.co/search-labs/blog/efficient-bitwise-matching-in-elasticsearch&#34;&gt;https://www.elastic.co/search-labs/blog/efficient-bitwise-matching-in-elasticsearch&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Automating the Import and Export of Kibana Saved Objects</title>
      <link>http://localhost:1313/posts/automating-the-import-and-export-of-kibana-saved-objects/</link>
      <pubDate>Fri, 03 May 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/automating-the-import-and-export-of-kibana-saved-objects/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;&lt;strong&gt;Introduction&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/kibana/current/introduction.html&#34;&gt;Kibana&lt;/a&gt; is an open-source data visualization and exploration tool used for log and time-series analytics, application monitoring, and operational intelligence use cases. It offers powerful and easy-to-use features that allow users to visualize data from Elasticsearch in various formats such as charts, tables, and maps.&lt;/p&gt;
&lt;p&gt;While Kibana offers a robust user interface for managing many tasks, certain operations can become tedious and time-consuming when done manually, especially for operations teams managing large and complex environments. One such operation is the migration of Kibana spaces and objects between environments—a task that can be critical in scenarios where clients cannot utilize the &lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/snapshot-restore.html&#34;&gt;snapshot/restore functionality&lt;/a&gt; provided by Elasticsearch.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Barcelona: A Personal Guide</title>
      <link>http://localhost:1313/posts/barcelona-a-personal-guide/</link>
      <pubDate>Sun, 21 Apr 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/barcelona-a-personal-guide/</guid>
      <description>&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://alexmarquardt.com/2024/04/21/barcelona-a-personal-guide/#motivation&#34;&gt;Motivation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://alexmarquardt.com/2024/04/21/barcelona-a-personal-guide/#welcome-to-barcelona&#34;&gt;Welcome to Barcelona!&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://alexmarquardt.com/2024/04/21/barcelona-a-personal-guide/#language-and-navigation&#34;&gt;Language and Navigation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://alexmarquardt.com/2024/04/21/barcelona-a-personal-guide/#choosing-your-base&#34;&gt;Choosing Your Base&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://alexmarquardt.com/2024/04/21/barcelona-a-personal-guide/#getting-around&#34;&gt;Getting Around&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://alexmarquardt.com/2024/04/21/barcelona-a-personal-guide/#must-see-attractions&#34;&gt;Must-See Attractions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://alexmarquardt.com/2024/04/21/barcelona-a-personal-guide/#dining&#34;&gt;Dining&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://alexmarquardt.com/2024/04/21/barcelona-a-personal-guide/#nightlife-in-barcelona&#34;&gt;Nightlife in Barcelona&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://alexmarquardt.com/2024/04/21/barcelona-a-personal-guide/#safety&#34;&gt;Safety&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://alexmarquardt.com/2024/04/21/barcelona-a-personal-guide/#cultural-insights-and-local-etiquette&#34;&gt;Cultural Insights and Local Etiquette&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://alexmarquardt.com/2024/04/21/barcelona-a-personal-guide/#biking-and-hiking-around-barcelona&#34;&gt;Biking and Hiking Around Barcelona&lt;/a&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://alexmarquardt.com/2024/04/21/barcelona-a-personal-guide/#biking-adventures&#34;&gt;Biking Adventures:&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://alexmarquardt.com/2024/04/21/barcelona-a-personal-guide/#hiking-escapes&#34;&gt;Hiking Escapes:&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://alexmarquardt.com/2024/04/21/barcelona-a-personal-guide/#day-and-weekend-trips&#34;&gt;Day and Weekend Trips&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://alexmarquardt.com/2024/04/21/barcelona-a-personal-guide/#conclusion&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;motivation&#34;&gt;Motivation&lt;/h2&gt;
&lt;p&gt;Originally from Canada, I have lived in Barcelona on and off since 2003. Over the years, many friends and acquaintances have asked for my recommendations on what to see and do in this beautiful city. To save time and ensure no detail is missed, I’ve compiled this comprehensive guide based on my personal experiences and research I&amp;rsquo;ve done over the years.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Re-directing Elasticsearch documents with out-of-range timestamps that (would) fail to get written into Time Series Data Streams</title>
      <link>http://localhost:1313/posts/catching-elasticsearch-documents-with-incorrect-timestamps-that-fail-to-get-written-into-time-series-data-streams/</link>
      <pubDate>Tue, 16 Apr 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/catching-elasticsearch-documents-with-incorrect-timestamps-that-fail-to-get-written-into-time-series-data-streams/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Elasticsearch &lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/tsds.html&#34;&gt;Time Series Data Streams (TSDS)&lt;/a&gt; are designed to provide an efficient and scalable way to handle time-based data within the Elasticsearch ecosystem. This feature is specifically optimized for storing, searching, and managing time-series data such as metrics, and events, where data is continuously indexed in chronological order. However, if events arrive with timestamps that fall outside of a pre-defined range, they will be lost.&lt;/p&gt;
&lt;p&gt;In this blog I will demonstrate logic that can be added to an Elasticsearch ingest pipeline which can be used to intercept documents that would be rejected by the TSDS index due to timestamp range issues, and to instead redirect them to a &amp;ldquo;failed&amp;rdquo; index. The documents that are redirected to the &amp;ldquo;failed&amp;rdquo; index may (for example) be used to raise alerts and examined.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Cut and paste a table from Google Sheets into an HTML document – no code&amp;nbsp;required</title>
      <link>http://localhost:1313/personal/cut-and-paste-a-table-from-google-sheets-into-an-html-document-no-code-required/</link>
      <pubDate>Mon, 10 Oct 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/personal/cut-and-paste-a-table-from-google-sheets-into-an-html-document-no-code-required/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;In a &lt;a href=&#34;https://airbyte.com/blog/understanding-data-replication-modes&#34;&gt;recent article&lt;/a&gt; that I wrote for &lt;a href=&#34;http://www.airbyte.com/&#34;&gt;Airbyte&lt;/a&gt; it was necessary for me to copy and paste a table from Google Sheets into &lt;a href=&#34;http://www.webflow.com/&#34;&gt;Webflow&lt;/a&gt;. Unfortunately, Webflow doesn’t currently support copy/paste of tables directly in its editor.&lt;/p&gt;
&lt;p&gt;In this blog, I present a workaround that can be used to convert a table from Google Sheets into HTML, which can then be written into a Webflow &lt;a href=&#34;https://university.webflow.com/lesson/custom-code-embed&#34;&gt;custom code block&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;acknowledgement&#34;&gt;Acknowledgement&lt;/h2&gt;
&lt;p&gt;Thank you to &lt;a href=&#34;https://www.swyx.io/&#34;&gt;Shawn Wang&lt;/a&gt; for providing the steps that can be used to copy and paste a table from Google Sheets into HTML so easily.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Using Logstash to scan inside event contents to replace sensitive data with a consistent hash</title>
      <link>http://localhost:1313/posts/using-logstash-to-hash-sensitive-text/</link>
      <pubDate>Thu, 20 Jan 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/using-logstash-to-hash-sensitive-text/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://www.elastic.co/logstash/&#34;&gt;Logstash&lt;/a&gt; is commonly used for transforming data before it is sent to another system for storage, and so it is often well positioned for finding and replacing sensitive text, as may be required for GDPR compliance.&lt;/p&gt;
&lt;p&gt;Therefore, in this blog I show how Logstash can make use of a ruby filter to scan through the contents of an event and to replace &lt;em&gt;each occurrence&lt;/em&gt; of sensitive text with the value of its hash.&lt;/p&gt;</description>
    </item>
    <item>
      <title>A summary of recent research on increasing lifespan</title>
      <link>http://localhost:1313/posts/a-summary-of-recent-research-on-increasing-lifespan/</link>
      <pubDate>Tue, 01 Jun 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/a-summary-of-recent-research-on-increasing-lifespan/</guid>
      <description>&lt;h2 id=&#34;authors&#34;&gt;Authors&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Ronald R. Marquardt&lt;/li&gt;
&lt;li&gt;Suzhen Li&lt;/li&gt;
&lt;li&gt;Alexander Marquardt&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In association with &lt;a href=&#34;https://annp.ca/&#34;&gt;All Natural Nutritional Products (ANNP) Inc.&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;This blog provides an overview of recent research in the field of ageing.&lt;/p&gt;
&lt;h2 id=&#34;a-brief-overview-of-the-book-lifespan-why-we-age--and-why-we-dont-have-to&#34;&gt;A brief overview of the book: &amp;ldquo;Lifespan: Why we age — and why we don&amp;rsquo;t have to&amp;rdquo;&lt;/h2&gt;
&lt;p&gt;David A. Sinclair and M. D. LaPlante have written a New York Times Bestseller called &lt;a href=&#34;https://lifespanbook.com/&#34;&gt;Lifespan: Why we age — and why we don&amp;rsquo;t have to&lt;/a&gt;. David Sinclair has also given many interviews and talks which can be found online.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Combining Elasticsearch stemmers and synonyms to improve search relevance</title>
      <link>http://localhost:1313/posts/combining-elasticsearch-stemmers-and-synonyms-to-improve-search-relevance/</link>
      <pubDate>Sat, 15 May 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/combining-elasticsearch-stemmers-and-synonyms-to-improve-search-relevance/</guid>
      <description>&lt;p&gt;This is now published on Elastic&amp;rsquo;s official blog. Please check it out at: &lt;a href=&#34;https://www.elastic.co/blog/improve-search-relevance-by-combining-elasticsearch-stemmers-and-synonyms&#34;&gt;https://www.elastic.co/blog/improve-search-relevance-by-combining-elasticsearch-stemmers-and-synonyms&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Driving Filebeat data into separate indices (uses legacy index templates)</title>
      <link>http://localhost:1313/posts/driving-filebeat-data-into-separate-indices-uses-legacy-index-templates/</link>
      <pubDate>Mon, 15 Mar 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/driving-filebeat-data-into-separate-indices-uses-legacy-index-templates/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;When driving data into &lt;a href=&#34;https://www.elastic.co/elasticsearch/&#34;&gt;Elasticsearch&lt;/a&gt; from &lt;a href=&#34;https://www.elastic.co/guide/en/beats/filebeat/current/filebeat-overview.html&#34;&gt;Filebeat&lt;/a&gt;, the default behaviour is for all data to be sent into the same destination index regardless of the source of the data. This may not always be desirable since data from different sources may have different access requirements , different retention policies, or different ingest processing requirements.&lt;/p&gt;
&lt;p&gt;In this post, we&amp;rsquo;ll use Filebeat to send data from separate sources into multiple indices, and then we&amp;rsquo;ll use &lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/index-lifecycle-management.html&#34;&gt;index lifecycle management (ILM)&lt;/a&gt;, &lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/7.11/indices-templates-v1.html&#34;&gt;&lt;em&gt;legacy&lt;/em&gt; index templates&lt;/a&gt;, and a &lt;a href=&#34;https://www.elastic.co/blog/new-way-to-ingest-part-1&#34;&gt;custom ingest pipeline&lt;/a&gt; to further control that data.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Using Kibana&#39;s Painless Lab (Beta) to test an ingest processor script</title>
      <link>http://localhost:1313/posts/using-kibanas-painless-lab-beta-to-test-an-ingest-processor-script/</link>
      <pubDate>Mon, 09 Nov 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/using-kibanas-painless-lab-beta-to-test-an-ingest-processor-script/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;In several previous blog posts I have shown how a Painless script can be used to process new documents as they are ingested into an Elasticsearch cluster. In each of these posts I have made use of the simulate pipeline API to test the Painless scripts.&lt;/p&gt;
&lt;p&gt;While developing such scripts, it may be helpful to use &lt;a href=&#34;https://www.elastic.co/guide/en/kibana/current/painlesslab.html&#34;&gt;Painless Lab&lt;/a&gt; (Beta) in Kibana to debug Painless scripts. In this blog I will show how to use Painless Lab to develop and debug custom scripts, and then show how these can be then easily copied into ingest pipelines.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Using Elasticsearch Painless scripting to recursively iterate through JSON fields</title>
      <link>http://localhost:1313/posts/using-elasticsearch-painless-scripting-to-iterate-through-fields/</link>
      <pubDate>Fri, 06 Nov 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/using-elasticsearch-painless-scripting-to-iterate-through-fields/</guid>
      <description>&lt;h2 id=&#34;authors&#34;&gt;Authors&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Alexander Marquardt&lt;/li&gt;
&lt;li&gt;Honza Kral&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/master/modules-scripting-painless.html&#34;&gt;Painless&lt;/a&gt;&lt;/em&gt; is a simple, secure scripting language designed specifically for use with Elasticsearch. It is the default scripting language for Elasticsearch and can safely be used for inline and stored scripts. In one of its many use cases, Painless can modify documents as they are ingested into your Elasticsearch cluster. In this use case, you may find that you would like to use Painless to evaluate every field in each document that is received by Elasticsearch. However, because of the hierarchical nature of JSON documents, how to iterate over all of the fields may be non-obvious.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Understanding and fixing &#34;too many script compilations&#34; errors in Elasticsearch</title>
      <link>http://localhost:1313/posts/elasticsearch-too-many-script-compilations/</link>
      <pubDate>Wed, 21 Oct 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/elasticsearch-too-many-script-compilations/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;When using Elasticsearch, in some rare instances you may see an error such as &amp;ldquo;Too many dynamic script compilations within X minutes&amp;rdquo;. Such an error may be caused by a poor script design &lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/master/modules-scripting-using.html#prefer-params&#34;&gt;where parameters are hard-coded&lt;/a&gt;. In other cases this may be due to the script cache being too small or the compilation limit being too low. In this article, I will show how to determine if these default limits are too low, and how these limits can be modified.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Using Logstash and Elasticsearch to calculate transaction duration in a microservices architecture</title>
      <link>http://localhost:1313/posts/using-logstash-and-elasticsearch-scripted-upserts-to-calculate-transaction-duration-from-out-of-order-events/</link>
      <pubDate>Wed, 16 Sep 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/using-logstash-and-elasticsearch-scripted-upserts-to-calculate-transaction-duration-from-out-of-order-events/</guid>
      <description>&lt;p&gt;September 16, 2020&lt;/p&gt;
&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Elasticsearch  allows you to unify your observability data in a powerful datastore so you can search and apply interactive analytics in real time to a huge number of use cases.&lt;/p&gt;
&lt;p&gt;In one such use case, you may be using Elasticsearch to monitor a system that is composed of multiple microservices that process a given transaction. For such a system, you may be collecting an event corresponding to when the first microservice in the system starts processing the transaction, and another event corresponding to when the last microservice in the system finishes processing the transaction. In such an approach, each event should include a field with the transaction identifier, which will allow multiple events corresponding to a single transaction to be combined for analysis.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Using Grok with Elasticsearch to add structure to your data</title>
      <link>http://localhost:1313/elastic/using-grok-with-elasticsearch-to-add-structure-to-your-data/</link>
      <pubDate>Mon, 13 Jul 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/elastic/using-grok-with-elasticsearch-to-add-structure-to-your-data/</guid>
      <description>&lt;p&gt;This article is available on Elastic&amp;rsquo;s blog as a 3-part series. Please check it out at the following URLs:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.elastic.co/blog/structuring-elasticsearch-data-with-grok-on-ingest-for-faster-analytics&#34;&gt;https://www.elastic.co/blog/structuring-elasticsearch-data-with-grok-on-ingest-for-faster-analytics&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.elastic.co/blog/slow-and-steady-how-to-build-custom-grok-patterns-incrementally&#34;&gt;https://www.elastic.co/blog/slow-and-steady-how-to-build-custom-grok-patterns-incrementally&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.elastic.co/blog/debugging-broken-grok-expressions-in-elasticsearch-ingest-processors&#34;&gt;https://www.elastic.co/blog/debugging-broken-grok-expressions-in-elasticsearch-ingest-processors&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    <item>
      <title>Storing ingest time and calculating ingest lag in Elasticsearch</title>
      <link>http://localhost:1313/posts/storing-ingest-time-and-calculating-ingest-lag-in-elasticsearch/</link>
      <pubDate>Tue, 02 Jun 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/storing-ingest-time-and-calculating-ingest-lag-in-elasticsearch/</guid>
      <description>&lt;p&gt;This article is available on Elastic&amp;rsquo;s blog at: &lt;a href=&#34;https://www.elastic.co/blog/calculating-ingest-lag-and-storing-ingest-time-in-elasticsearch-to-improve-observability&#34;&gt;https://www.elastic.co/blog/calculating-ingest-lag-and-storing-ingest-time-in-elasticsearch-to-improve-observability&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Using boolean queries to improve search relevancy in Elasticsearch</title>
      <link>http://localhost:1313/elastic/a-simple-and-powerful-technique-to-improve-search-relevancy-in-elasticsearch/</link>
      <pubDate>Tue, 12 May 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/elastic/a-simple-and-powerful-technique-to-improve-search-relevancy-in-elasticsearch/</guid>
      <description>&lt;p&gt;Page moved to &lt;a href=&#34;https://alexmarquardt.com/using-boolean-queries-to-improve-search-relevancy-in-elasticsearch/&#34;&gt;https://alexmarquardt.com/using-boolean-queries-to-improve-search-relevancy-in-elasticsearch/&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Using boolean queries to improve search relevance in Elasticsearch</title>
      <link>http://localhost:1313/elastic/using-boolean-queries-to-improve-search-relevancy-in-elasticsearch/</link>
      <pubDate>Fri, 01 May 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/elastic/using-boolean-queries-to-improve-search-relevancy-in-elasticsearch/</guid>
      <description>&lt;p&gt;This article is available at: &lt;a href=&#34;https://www.elastic.co/blog/how-to-improve-elasticsearch-search-relevance-with-boolean-queries&#34;&gt;https://www.elastic.co/blog/how-to-improve-elasticsearch-search-relevance-with-boolean-queries&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Using slow logs in Elastic Cloud Enterprise</title>
      <link>http://localhost:1313/elastic/using-slow-logs-in-elastic-cloud-enterprise/</link>
      <pubDate>Sun, 26 Apr 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/elastic/using-slow-logs-in-elastic-cloud-enterprise/</guid>
      <description>&lt;p&gt;April 26, 2020&lt;/p&gt;
&lt;h1 id=&#34;authors&#34;&gt;Authors&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Tom Schreiber&lt;/li&gt;
&lt;li&gt;Alex Marquardt&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;version&#34;&gt;Version&lt;/h1&gt;
&lt;p&gt;This blog article is based on ECE 2.4.3.&lt;/p&gt;
&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/cloud-enterprise/2.4/Elastic-Cloud-Enterprise-overview.html&#34;&gt;Elastic Cloud Enterprise&lt;/a&gt; (ECE) is a platform designed to ease the management, deployment, and configuration of multiple Elasticsearch clusters through a single administrative user interface. ECE, is the same product that powers the &lt;a href=&#34;https://www.elastic.co/elasticsearch/service&#34;&gt;Elasticsearch Service&lt;/a&gt; hosted offering, and is available for installation on customer-managed servers. ECE can be deployed anywhere - on public or private clouds, virtual machines, or even on bare metal hardware. Once installed, ECE allows Elasticsearch clusters to be created, upgraded, or deleted with the click of a button.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Using Elastic machine learning to detect anomalies in derivative values</title>
      <link>http://localhost:1313/elastic/using-elastic-machine-learning-to-detect-anomalies-in-derivative-values/</link>
      <pubDate>Tue, 21 Apr 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/elastic/using-elastic-machine-learning-to-detect-anomalies-in-derivative-values/</guid>
      <description>&lt;p&gt;April 21, 2020&lt;/p&gt;
&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;In this blog, we use Elastic machine learning (ML) and derivative aggregations to detect sudden unexpected increases or decreases in the &lt;em&gt;rate-of-change&lt;/em&gt; of CPU load on servers that are monitored by &lt;a href=&#34;https://www.elastic.co/guide/en/beats/metricbeat/7.6/metricbeat-overview.html&#34;&gt;Metricbeat&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In order to make this blog easier to follow and the results easy to recreate, we abstract away the requirement for driving data from Metricbeat, and instead generate &amp;ldquo;fake&amp;rdquo; Metricbeat data using a Python script that drives data into Elasticsearch.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Using the Elasticsearch Enrich Processor with CSV data</title>
      <link>http://localhost:1313/elastic/enriching-elasticsearch-documents-with-data-from-csv-files/</link>
      <pubDate>Sat, 21 Mar 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/elastic/enriching-elasticsearch-documents-with-data-from-csv-files/</guid>
      <description>&lt;p&gt;This article is available at: &lt;a href=&#34;https://www.elastic.co/blog/how-to-enrich-logs-and-metrics-using-an-elasticsearch-ingest-node&#34;&gt;https://www.elastic.co/blog/how-to-enrich-logs-and-metrics-using-an-elasticsearch-ingest-node&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Converting CSV to JSON in Filebeat</title>
      <link>http://localhost:1313/posts/converting-csv-to-json-in-filebeat/</link>
      <pubDate>Tue, 17 Mar 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/converting-csv-to-json-in-filebeat/</guid>
      <description>&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Many organisations use excel files for creating and storing important data. For various reasons it may be useful to import such data into Elasticsearch. For example, one may need to get &lt;a href=&#34;https://en.wikipedia.org/wiki/Master_data&#34;&gt;Master Data&lt;/a&gt; that is created in a spreadsheet into Elasticsearch where it could be used for &lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/7.x/ingest-enriching-data.html&#34;&gt;enriching Elasticsearch documents&lt;/a&gt;. Or one may wish to use Elasticsearch and Kibana for analysing a dataset that is only available in a spreadsheet. In such cases, one option is to use &lt;a href=&#34;https://www.elastic.co/guide/en/beats/filebeat/7.6/filebeat-overview.html&#34;&gt;Filebeat&lt;/a&gt; for uploading such CSV data into an Elasticsearch cluster.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Enriching data with the Logstash translate filter</title>
      <link>http://localhost:1313/elastic/enriching-data-with-the-logstash-translate-filter/</link>
      <pubDate>Fri, 06 Mar 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/elastic/enriching-data-with-the-logstash-translate-filter/</guid>
      <description>&lt;p&gt;March 6, 2020&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://www.elastic.co/logstash&#34;&gt;Logstash&lt;/a&gt; is an open source, server-side data processing pipeline that ingests data from a multitude of sources, transforms it, and then sends it to one or more outputs. One use of Logstash is for enriching data before sending it to Elasticsearch.&lt;/p&gt;
&lt;p&gt;Logstash supports several different &lt;a href=&#34;https://www.elastic.co/guide/en/logstash/current/lookup-enrichment.html#geoip-def&#34;&gt;lookup plugin filters&lt;/a&gt; that can be used for enriching data. Many of these rely on components that are external to the Logstash pipeline for storing enrichment data. On the other hand, the &lt;a href=&#34;https://www.elastic.co/guide/en/logstash/current/plugins-filters-translate.html&#34;&gt;translate filter plugin&lt;/a&gt; can be used for looking up data and enriching documents without dependencies. Therefore, in this blog article I focus on using Logstash with the translate filter plugin for enriching data.&lt;/p&gt;</description>
    </item>
    <item>
      <title>How to create maintainable and reusable logstash pipelines</title>
      <link>http://localhost:1313/elastic/how-to-create-maintainable-and-reusable-logstash-pipelines/</link>
      <pubDate>Wed, 26 Feb 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/elastic/how-to-create-maintainable-and-reusable-logstash-pipelines/</guid>
      <description>&lt;p&gt;This article is available at: &lt;a href=&#34;https://www.elastic.co/blog/how-to-create-maintainable-and-reusable-logstash-pipelines&#34;&gt;https://www.elastic.co/blog/how-to-create-maintainable-and-reusable-logstash-pipelines&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Using Logstash and Elasticsearch scripted upserts to transform eCommerce purchasing data</title>
      <link>http://localhost:1313/posts/logstash-and-elasticsearch-painless-scripted-upserts-transform-data/</link>
      <pubDate>Tue, 17 Dec 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/logstash-and-elasticsearch-painless-scripted-upserts-transform-data/</guid>
      <description>&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/logstash/7.5/introduction.html&#34;&gt;Logstash&lt;/a&gt; is a tool that can be used to collect, process, and forward events to Elasticsearch. In order to demonstrate the power of Logstash when used in conjunction with Elasticsearch’s &lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/7.5/docs-update.html#scripted_upsert&#34;&gt;scripted upserts&lt;/a&gt;, I will show you how to create a near-real-time &lt;a href=&#34;https://www.elastic.co/elasticon/2015/sf/building-entity-centric-indexes&#34;&gt;entity-centric index&lt;/a&gt;. Once data is transformed into an entity-centric index, many kinds of analysis become possible with simple (cheap) queries rather than more computationally intensive aggregations.&lt;/p&gt;
&lt;p&gt;As a note, using the approach demonstrated here would result in documents similar to those generated by &lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/7.5/transforms.html&#34;&gt;Elasticsearch transforms&lt;/a&gt;. Nevertheless, the technique that is documented has not been benchmarked against Elasticsearch transforms, as the main goal of this blog is to demonstrate the power and flexibility of Logstash combined with scripted upserts.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Emulating transactional functionality in Elasticsearch with two-phase commits</title>
      <link>http://localhost:1313/posts/emulating-transactional-functionality-in-elasticsearch-with-two-phase-commits/</link>
      <pubDate>Thu, 05 Dec 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/emulating-transactional-functionality-in-elasticsearch-with-two-phase-commits/</guid>
      <description>&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Elasticsearch supports atomic create, update, and delete operations at the individual document level, but does not have built-in &lt;a href=&#34;https://www.elastic.co/blog/found-elasticsearch-as-nosql#transactions&#34;&gt;support for multi-document transactions&lt;/a&gt;. Although Elasticsearch does not position itself as a system of record for storing data, in some cases it may be necessary to modify multiple documents as a single cohesive unit. Therefore, in this blog post we present a &lt;a href=&#34;https://en.wikipedia.org/wiki/Two-phase_commit_protocol&#34;&gt;two-phase commit protocol&lt;/a&gt; which can be used to &lt;em&gt;emulate&lt;/em&gt; multi-document transactions.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Converting local time to ISO 8601 time in Elasticsearch</title>
      <link>http://localhost:1313/posts/converting-local-time-to-iso-8601-time-in-elasticsearch/</link>
      <pubDate>Wed, 16 Oct 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/converting-local-time-to-iso-8601-time-in-elasticsearch/</guid>
      <description>&lt;p&gt;This article is available at: &lt;a href=&#34;https://www.elastic.co/blog/converting-local-time-to-iso-8601-time-in-elasticsearch&#34;&gt;https://www.elastic.co/blog/converting-local-time-to-iso-8601-time-in-elasticsearch&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Es Local Indexer - using Elasticsearch for searching locally stored documents</title>
      <link>http://localhost:1313/elastic/es-local-indexer-using-elasticsearch-for-searching-locally-stored-documents/</link>
      <pubDate>Thu, 08 Aug 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/elastic/es-local-indexer-using-elasticsearch-for-searching-locally-stored-documents/</guid>
      <description>&lt;p&gt;Moved to: &lt;a href=&#34;https://alexmarquardt.com/es-local-indexer-desktop-search-built-with-elasticsearch/&#34;&gt;https://alexmarquardt.com/es-local-indexer-desktop-search-built-with-elasticsearch/&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>ES Local Indexer – Desktop search powered by Elasticsearch</title>
      <link>http://localhost:1313/elastic/es-local-indexer-desktop-search-built-with-elasticsearch/</link>
      <pubDate>Thu, 08 Aug 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/elastic/es-local-indexer-desktop-search-built-with-elasticsearch/</guid>
      <description>&lt;p&gt;August 7, 2019&lt;/p&gt;
&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Elasticsearch provides search functionality for some of the most important websites in the world including &lt;a href=&#34;https://blog.wikimedia.org/2014/01/06/wikimedia-moving-to-elasticsearch/&#34;&gt;Wikimedia (i.e. Wikipedia)&lt;/a&gt;, &lt;a href=&#34;https://www.elastic.co/videos/ebay-and-elasticsearch-this-is-not-small-data&#34;&gt;eBay&lt;/a&gt;, &lt;a href=&#34;https://engineeringblog.yelp.com/2017/06/moving-yelps-core-business-search-to-elasticsearch.html&#34;&gt;Yelp&lt;/a&gt;, &lt;a href=&#34;https://www.elastic.co/elasticon/conf/2017/sf/tinder-using-the-elastic-stack-to-make-connections-around-the-world&#34;&gt;Tinder&lt;/a&gt;, and many others. Elasticsearch is super scalable, which means that just as easily as it can be scaled it up for use in huge complex systems, it can also be scaled down for use in smaller projects.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/alexander-marquardt/es_local_indexer&#34;&gt;ES Local Indexer&lt;/a&gt; is a small desktop search application that runs on top of a local Elasticsearch installation. It indexes HTML documents into Elasticsearch and provides an intuitive browser-based interface for searching through the ingested documents. The ES Local Indexer project consists of two main components:&lt;/p&gt;</description>
    </item>
    <item>
      <title>How to mitigate hangovers</title>
      <link>http://localhost:1313/posts/how-to-mitigate-hangovers/</link>
      <pubDate>Tue, 30 Jul 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/how-to-mitigate-hangovers/</guid>
      <description>&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Many natural products exist that are purported to be able to prevent hangovers, but unfortunately when one talks about natural hangover remedies it is difficult to find many well funded scientific studies that validate or refute such claims. This is at least in part because few if any companies are willing to invest millions of dollars investigating and running clinical trials to validate natural products that cannot then be patented to make a profit from.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Financial implications of exercising share options</title>
      <link>http://localhost:1313/posts/financial-implications-of-exercising-share-options/</link>
      <pubDate>Sat, 27 Jul 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/financial-implications-of-exercising-share-options/</guid>
      <description>&lt;h1 id=&#34;disclaimer&#34;&gt;Disclaimer&lt;/h1&gt;
&lt;p&gt;I am not an accountant and this article &lt;strong&gt;should not be considered as financial or tax advice&lt;/strong&gt;. I am providing analysis and calculations which may be used at your own peril. This article is written to demonstrate basic concepts, and does not account for country-specific tax laws or company-specific share option details. Your individual situation may invalidate some or all of the arguments and/or calculations made in this blog post.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Counting unique beats agents sending data into Elasticsearch</title>
      <link>http://localhost:1313/posts/counting-unique-beats-agents-elasticsearch/</link>
      <pubDate>Thu, 18 Jul 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/counting-unique-beats-agents-elasticsearch/</guid>
      <description>&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;When using Beats with Elasticsearch, it may be useful to keep track of how many unique agents are sending data into an Elasticsearch cluster, and how many documents each agent is submitting. Such information for example could be useful for detecting if beats agents are behaving as expected.&lt;/p&gt;
&lt;p&gt;In this blog post, I first discuss how to efficiently specify a filter for documents corresponding to a particular time range, followed by several methods for detecting how many beats agents are sending documents to Elasticsearch within the specified time range.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Improving the performance of Logstash persistent queues</title>
      <link>http://localhost:1313/posts/improving-the-performance-of-logstash-persistent-queues/</link>
      <pubDate>Sat, 15 Jun 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/improving-the-performance-of-logstash-persistent-queues/</guid>
      <description>&lt;p&gt;This article is available at: &lt;a href=&#34;https://www.elastic.co/blog/using-parallel-logstash-pipelines-to-improve-persistent-queue-performance&#34;&gt;https://www.elastic.co/blog/using-parallel-logstash-pipelines-to-improve-persistent-queue-performance&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Patents</title>
      <link>http://localhost:1313/professional/patents/</link>
      <pubDate>Fri, 29 Mar 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/professional/patents/</guid>
      <description>&lt;h4 id=&#34;method-and-system-for-estimating-the-reliability-of-blacklists-of-botnet-infected-computers&#34;&gt;Method and system for estimating the reliability of blacklists of botnet-infected computers&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;US patent 8,516,595.&lt;/li&gt;
&lt;li&gt;Issued Aug 20, 2013&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO1&amp;amp;Sect2=HITOFF&amp;amp;d=PALL&amp;amp;p=1&amp;amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.htm&amp;amp;r=1&amp;amp;f=G&amp;amp;l=50&amp;amp;s1=8516595.PN.&amp;amp;OS=PN/8516595&amp;amp;RS=PN/8516595&#34;&gt;See patent.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;versatile-logic-element-and-logic-array-block&#34;&gt;Versatile logic element and logic array block&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;US patent 7,218,133&lt;/li&gt;
&lt;li&gt;Issued May 15, 2007 &lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO1&amp;amp;Sect2=HITOFF&amp;amp;d=PALL&amp;amp;p=1&amp;amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.htm&amp;amp;r=1&amp;amp;f=G&amp;amp;l=50&amp;amp;s1=7218133.PN.&amp;amp;OS=PN/7218133&amp;amp;RS=PN/7218133&#34;&gt;See patent.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;routing-architecture-for-a-programmable-logic-device&#34;&gt;Routing Architecture For A Programmable Logic Device&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;US patent 6,970,014 &lt;/li&gt;
&lt;li&gt;Issued Nov 29, 2005&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO1&amp;amp;Sect2=HITOFF&amp;amp;d=PALL&amp;amp;p=1&amp;amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.htm&amp;amp;r=1&amp;amp;f=G&amp;amp;l=50&amp;amp;s1=6970014.PN.&amp;amp;OS=PN/6970014&amp;amp;RS=PN/6970014&#34;&gt;See patent.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    <item>
      <title>Publications</title>
      <link>http://localhost:1313/professional/publications/</link>
      <pubDate>Fri, 22 Mar 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/professional/publications/</guid>
      <description>&lt;h2 id=&#34;book&#34;&gt;Book&lt;/h2&gt;
&lt;h4 id=&#34;architecture-and-cad-for-deep-sub-micron-fpgas&#34;&gt;Architecture and CAD for Deep Sub-Micron FPGAs&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Mar 1999 &amp;ndash; This book covers the software and hardware that is used for architecting and programming/re-configuring FPGAs.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.amazon.com/Architecture-Deep-Submicron-Springer-International-Engineering/dp/0792384601?lipi=urn%3Ali%3Apage%3Ad_flagship3_profile_view_base%3BJQDFjH2rTFyqLTVXSfr%2Bqg%3D%3D&#34;&gt;See book on Amazon.com.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://scholar.google.co.uk/scholar?cites=5046844827750126682&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en&#34;&gt;Cited by 1402 scientific publications&lt;/a&gt; as of October 2017.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;thesis&#34;&gt;Thesis&lt;/h2&gt;
&lt;h4 id=&#34;cluster-based-architecture-timing-driven-packing-and-timing-driven-placement-for-fpgas&#34;&gt;Cluster-Based Architecture, Timing-Driven Packing, and Timing-Driven Placement for FPGAs&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Apr 1999 &amp;ndash; M.A.Sc Thesis - National Library of Canada.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.collectionscanada.ca/obj/s4/f2/dsk1/tape8/PQDD_0004/MQ45993.pdf&#34;&gt;See publication.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://scholar.google.co.uk/scholar?cites=5625098770910011035&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en&#34;&gt;Cited by 15 scientific publications&lt;/a&gt; as of October 2017.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;scientific-papers&#34;&gt;Scientific Papers&lt;/h2&gt;
&lt;h4 id=&#34;the-stratix-ii-logic-and-routing-architecture&#34;&gt;The Stratix II Logic and Routing Architecture&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Nov 2005  -- ACM/Sigda 13th International Symposium on Field-Programmabel Gate Arrays&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.eecg.toronto.edu/~jayar/pubs/lewis/lewisfpga05.pdf&#34;&gt;See publication.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://scholar.google.co.uk/scholar?cites=5968923824677940858&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en&#34;&gt;Cited by 213 scientific publications&lt;/a&gt; as of October 2017.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;the-stratix-routing-and-logic-architecture&#34;&gt;The Stratix Routing and Logic Architecture&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Feb 2003  -- ACM/Sigda International Symposium on Field-Programmable Gate Arrays, 2003&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.eecg.utoronto.ca/~vaughn/papers/fpga_2003.pdf&#34;&gt;See publication.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Voted as one of the &lt;a href=&#34;http://tcfpga.org/fpga20/fpga20.html&#34;&gt;25 most significant FPGA papers of the past 20 years&lt;/a&gt; at the 20th anniversary of the International Symposium on Field-Programmable Gate Arrays in 2012. &lt;a href=&#34;http://tcfpga.org/fpga20/p222.pdf&#34;&gt;See endorsement.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://scholar.google.co.uk/scholar?cites=14159395481451854012&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en&#34;&gt;Cited by 146 scientific publications&lt;/a&gt; as of October 2017.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;speed-and-area-trade-offs-in-cluster-based-fpga-architectures&#34;&gt;Speed and Area Trade-Offs in Cluster-Based FPGA Architectures&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Feb 2000  -- IEEE Transactions on VLSI&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.eecg.toronto.edu/~vaughn/papers/tvlsi2000_arm.pdf&#34;&gt;See publication.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://scholar.google.co.uk/scholar?cites=12206654961109400147&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en&#34;&gt;Cited by 72 scientific publications&lt;/a&gt; as of October 2017.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;timing-driven-placement-for-fpgas&#34;&gt;Timing-Driven Placement for FPGAs&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Feb 2000 &amp;ndash; Proc. 8th. ACM/SIGDA Intl. Symposium on FPGAs.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.eecg.toronto.edu/~vaughn/papers/fpga2000_arm.pdf?lipi=urn%3Ali%3Apage%3Ad_flagship3_profile_view_base%3BJQDFjH2rTFyqLTVXSfr%2Bqg%3D%3D&#34;&gt;See publication.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Voted as one of the &lt;a href=&#34;http://tcfpga.org/fpga20/fpga20.html&#34;&gt;25 most significant FPGA papers of the past 20 years&lt;/a&gt; at the 20th anniversary of the International Symposium on Field-Programmable Gate Arrays in 2012. &lt;a href=&#34;http://tcfpga.org/fpga20/p174.pdf&#34;&gt;See endorsement.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://scholar.google.co.uk/scholar?cites=9315566072038561579&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en&#34;&gt;Cited by 285 scientific publications&lt;/a&gt; as of October 2017.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;using-cluster-based-logic-blocks-and-timing-driven-packing-to-improve-fpga-speed-and-density&#34;&gt;Using Cluster Based Logic Blocks and Timing-Driven Packing to Improve FPGA Speed and Density&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Feb 1999  -- Proc. 7th ACM/SIGDA Intl. Symposium on FPGAs&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www2.engr.arizona.edu/~ece506/readings/project-reading/6-cad/fpga99marq.pdf&#34;&gt;See publication.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Voted as one of the &lt;a href=&#34;http://tcfpga.org/fpga20/fpga20.html&#34;&gt;25 most significant FPGA papers of the past 20 years&lt;/a&gt; at the 20th anniversary of the International Symposium on Field-Programmable Gate Arrays in 2012. &lt;a href=&#34;http://tcfpga.org/fpga20/p138.pdf&#34;&gt;See endorsement.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://scholar.google.co.uk/scholar?cites=253764427430804918&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&amp;amp;hl=en&#34;&gt;Cited by 264 scientific publications&lt;/a&gt; as of October 2017.&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    <item>
      <title>Debugging Elasticsearch and Lucene with IntelliJ IDEA</title>
      <link>http://localhost:1313/posts/debugging-elasticsearch-and-lucene-with-intellij-idea/</link>
      <pubDate>Sat, 02 Feb 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/debugging-elasticsearch-and-lucene-with-intellij-idea/</guid>
      <description>&lt;p&gt;This article can be found at: &lt;a href=&#34;https://www.elastic.co/blog/how-to-debug-elasticsearch-source-code-in-intellij-idea&#34;&gt;https://www.elastic.co/blog/how-to-debug-elasticsearch-source-code-in-intellij-idea&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>A step-by-step guide to enabling security, TLS/SSL, and PKI authentication in Elasticsearch</title>
      <link>http://localhost:1313/posts/security-tls-ssl-pki-authentication-in-elasticsearch/</link>
      <pubDate>Mon, 05 Nov 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/security-tls-ssl-pki-authentication-in-elasticsearch/</guid>
      <description>&lt;p&gt;This article is available at: &lt;a href=&#34;https://www.elastic.co/blog/elasticsearch-security-configure-tls-ssl-pki-authentication&#34;&gt;https://www.elastic.co/blog/elasticsearch-security-configure-tls-ssl-pki-authentication&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>How to tune Elasticsearch for aggregation performance</title>
      <link>http://localhost:1313/elastic/how-to-tune-elasticsearch-for-aggregation-performance/</link>
      <pubDate>Tue, 02 Oct 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/elastic/how-to-tune-elasticsearch-for-aggregation-performance/</guid>
      <description>&lt;p&gt;October 2, 2018&lt;/p&gt;
&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;By default, Elasticsearch is tuned for the best trade-off between write performance and query performance for the majority of use cases. In this blog posting we cover some parameters that can be configured to improve query-time aggregation performance, with &lt;em&gt;some&lt;/em&gt; of these improvements coming at &lt;em&gt;the expense of write performance.&lt;/em&gt; &lt;/p&gt;
&lt;p&gt;Note that this blog posting does not present anything that is not already documented in other locations. The goal here is to pull together relevant information into a small and digestible posting that provides a few pointers on how to improve slow Elasticsearch aggregations.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Using Logstash to drive filtered data from a single source into multiple output destinations</title>
      <link>http://localhost:1313/posts/using-logstash-to-drive-filtered-data-from-a-single-source-into-multiple-output-destinations/</link>
      <pubDate>Fri, 31 Aug 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/using-logstash-to-drive-filtered-data-from-a-single-source-into-multiple-output-destinations/</guid>
      <description>&lt;p&gt;This article is available at: &lt;a href=&#34;https://www.elastic.co/blog/using-logstash-to-split-data-and-send-it-to-multiple-outputs&#34;&gt;https://www.elastic.co/blog/using-logstash-to-split-data-and-send-it-to-multiple-outputs&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Using Logstash prune capabilities to whitelist sub-documents</title>
      <link>http://localhost:1313/posts/using-logstash-prune-capabilities-to-whitelist-sub-documents/</link>
      <pubDate>Tue, 28 Aug 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/using-logstash-prune-capabilities-to-whitelist-sub-documents/</guid>
      <description>&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;
&lt;p&gt;Logstash&amp;rsquo;s &lt;a href=&#34;https://www.elastic.co/guide/en/logstash/current/plugins-filters-prune.html&#34;&gt;prune filter plugin&lt;/a&gt; can make use of whitelists to ensure that only specific desired fields are output from Logstash, and that all other fields are dropped. In this blog post we demonstrate the use of Logstash to whitelist desired fields and desired sub-documents before indexing into Elasticsearch.&lt;/p&gt;
&lt;h1 id=&#34;example-input-file&#34;&gt;Example input file&lt;/h1&gt;
&lt;p&gt;As an input to Logstash, we use a CSV file that contains stock market trades. A few example CSV stock market trades are given below. &lt;/p&gt;</description>
    </item>
    <item>
      <title>Deduplicating documents in Elasticsearch</title>
      <link>http://localhost:1313/posts/deduplicating-documents-in-elasticsearch/</link>
      <pubDate>Mon, 23 Jul 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/deduplicating-documents-in-elasticsearch/</guid>
      <description>&lt;p&gt;This article is available at: &lt;a href=&#34;https://www.elastic.co/blog/how-to-find-and-remove-duplicate-documents-in-elasticsearch&#34;&gt;https://www.elastic.co/blog/how-to-find-and-remove-duplicate-documents-in-elasticsearch&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Trade-offs to consider when storing binary data in MongoDB</title>
      <link>http://localhost:1313/posts/trade-offs-to-consider-when-storing-binary-data-in-mongodb/</link>
      <pubDate>Thu, 02 Mar 2017 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/trade-offs-to-consider-when-storing-binary-data-in-mongodb/</guid>
      <description>&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;When using MongoDB there are several approaches that make it easy to store and retrieve binary data, but it is not always clear which approach is the most appropriate for a given application. Therefore, in this blog post I discuss several methods for storing binary data when using MongoDB and the trade-offs associated with each method. Many of the trade-offs discussed here would likely apply to most other databases as well.&lt;/p&gt;</description>
    </item>
    <item>
      <title>How to generate unique identifiers for use with MongoDB</title>
      <link>http://localhost:1313/posts/how-to-generate-unique-identifiers-for-use-with-mongodb/</link>
      <pubDate>Mon, 30 Jan 2017 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/how-to-generate-unique-identifiers-for-use-with-mongodb/</guid>
      <description>&lt;h1 id=&#34;standard_&#34;&gt;&lt;img alt=&#34;standard_barcodes&#34; loading=&#34;lazy&#34; src=&#34;http://localhost:1313/posts/how-to-generate-unique-identifiers-for-use-with-mongodb/images/standard_barcodes.jpg&#34;&gt;&lt;/h1&gt;
&lt;p&gt;This blog article has been re-published with my permission by MongoDB at &lt;a href=&#34;https://www.mongodb.com/blog/post/generating-globally-unique-identifiers-for-use-with-mongodb&#34;&gt;https://www.mongodb.com/blog/post/generating-globally-unique-identifiers-for-use-with-mongodb&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;motivation&#34;&gt;Motivation&lt;/h1&gt;
&lt;p&gt;By default, MongoDB generates a unique &lt;a href=&#34;https://docs.mongodb.com/manual/reference/method/ObjectId/&#34;&gt;ObjectID&lt;/a&gt; identifier that is assigned to the _id field in a new document before writing that document to the database. In many cases the default unique identifiers assigned by MongoDB will meet application requirements. However, in some cases an application may need to create custom unique identifiers, such as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The application may require unique identifiers with a precise number of digits. For example, unique 12 digit identifiers might be required for bank account numbers.&lt;/li&gt;
&lt;li&gt;Unique identifiers may need to be generated in a monotonically increasing and continuous sequential order.&lt;/li&gt;
&lt;li&gt;Unique identifiers may need to be independent of a specific database vendor.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Due to the multi-threaded and distributed nature of modern applications, it is not always a straightforward task to generate unique identifiers that satisfy application requirements.&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:1313/about/about/</link>
      <pubDate>Wed, 25 Jan 2017 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/about/about/</guid>
      <description>&lt;h1 id=&#34;about-the-author&#34;&gt;About the Author&lt;/h1&gt;
&lt;h2 id=&#34;senior-principal-architect--genai--search&#34;&gt;Senior Principal Architect | GenAI &amp;amp; Search&lt;/h2&gt;
&lt;p&gt;I work on complex technical systems where performance, scale, and real-world constraints intersect. My focus is on architectural decision-making in distributed search and AI platforms, identifying structural risks, design trade-offs, and system behaviors that shape reliability and performance at scale.&lt;/p&gt;
&lt;p&gt;In my current role at Elastic, I operate at enterprise scale across GenAI and Search. I apply systems-level reasoning to high-impact problems, with an emphasis on creating reusable architectural assets, including patterns, middleware, tools, and delivery models. This reduces recurring escalations and improves how teams design, operate, and reason about similar systems over time.&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:1313/pages/welcome-to-alexmarquardt-com/</link>
      <pubDate>Wed, 25 Jan 2017 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/pages/welcome-to-alexmarquardt-com/</guid>
      <description>&lt;h1 id=&#34;about-this-site&#34;&gt;About this site&lt;/h1&gt;
&lt;p&gt;This site brings together technical writing focused on search, data pipelines, and distributed systems at enterprise scale. It is informed by real production systems and reflects recurring patterns, trade-offs, and architectural decisions observed across system design, deployment, and long-term operation.&lt;/p&gt;
&lt;p&gt;The material emphasizes architectural reasoning for large-scale systems. It examines how relevance models, reliability mechanisms, and ingest pipelines behave under real-world constraints, with attention to system-level decisions that shape scalability, maintainability, and long-term operational effort.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Contact</title>
      <link>http://localhost:1313/professional/contact/</link>
      <pubDate>Wed, 25 Jan 2017 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/professional/contact/</guid>
      <description>&lt;p&gt;Alexander Marquardt’s LinkedIn profile can be found at &lt;a href=&#34;https://www.linkedin.com/in/alexandermarquardt/&#34;&gt;https://www.linkedin.com/in/alexandermarquardt/&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>How to manually perform a point in time restore in MongoDB</title>
      <link>http://localhost:1313/posts/mongodb-point-in-time-restore/</link>
      <pubDate>Wed, 25 Jan 2017 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/mongodb-point-in-time-restore/</guid>
      <description>&lt;h2 id=&#34;human-error-in-finance&#34;&gt;&lt;img alt=&#34;human-error-in-finance&#34; loading=&#34;lazy&#34; src=&#34;http://localhost:1313/posts/mongodb-point-in-time-restore/images/human-error-in-finance.jpg&#34;&gt;&lt;/h2&gt;
&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;While MongoDB provides high-availability and data durability through &lt;a href=&#34;https://docs.mongodb.com/manual/replication/&#34;&gt;automatic replication&lt;/a&gt; of data to multiple servers, this replication does not protect the database against human or application errors. For example, if an administrator drops a database, the drop operation will be replicated across the MongoDB deployment, and data will be deleted. If such an event occurs through human or application error, then data will have to be retrieved from backups.&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:1313/pages/_drafts/id-1088/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/pages/_drafts/id-1088/</guid>
      <description>&lt;p&gt;Enriching Elasticsearch documents with CSV data&lt;/p&gt;</description>
    </item>
    <item>
      <title>Case-insensitive character filter in Elasticsearch</title>
      <link>http://localhost:1313/posts/_drafts/id-1402/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/_drafts/id-1402/</guid>
      <description>&lt;h1 id=&#34;background&#34;&gt;Background&lt;/h1&gt;
&lt;p&gt;When ingesting code into Elasticsearch, you may have certain words that should not be split up. For example, the word &amp;ldquo;X-Pack&amp;rdquo; should likely be stored as a single token. However, due to the way that most &lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/7.8/analyzer-anatomy.html&#34;&gt;analyzers&lt;/a&gt; work, this &amp;ldquo;word&amp;rdquo; would be tokenized into two words: &amp;ldquo;X&amp;rdquo; and &amp;ldquo;Pack&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;Because an analyzer consists of &lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/7.8/analyzer-anatomy.html#analyzer-anatomy-character-filters&#34;&gt;character filters&lt;/a&gt;, followed by a &lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/7.8/analyzer-anatomy.html#analyzer-anatomy-tokenizer&#34;&gt;tokenizer&lt;/a&gt;, followed by &lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/7.8/analyzer-anatomy.html#analyzer-anatomy-token-filters&#34;&gt;token filters&lt;/a&gt;, if we want to prevent a word such as X-Pack from being split apart into multiple tokens, we can design a custom character filter to modify the word &lt;em&gt;before&lt;/em&gt; it gets to the tokenizer.&lt;/p&gt;</description>
    </item>
    <item>
      <title>How to change an index pattern used by a Kibana visualization</title>
      <link>http://localhost:1313/posts/_drafts/id-1631/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/_drafts/id-1631/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Kibana visualizations are built to work on a specific index pattern. However, the underlying index pattern used for the visualization may change. If this happens, for many of the visualizations (Area, Pie, etc.), there is currently not a clean way to change the underlying index pattern.&lt;/p&gt;
&lt;p&gt;In this blog, I will demonstrate how to change the index pattern that is used for visualizations that are already present in your dashboard.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
